{
  "generatedAt": "2025-11-19T21:05:52.899Z",
  "count": 89,
  "items": [
    {
      "id": "https://www.therobotreport.com/?p=586092",
      "title": "Bal Seal offers pre-certified IP67, IP69 seals for robots",
      "url": "https://www.therobotreport.com/bal-seal-offers-pre-certified-ip67-ip69-seals-for-robots/",
      "publishedAt": "Wed, 19 Nov 2025 18:38:54 +0000",
      "summary": "This pre-certification eliminates the need for in-house or outsourced seal testing, saving time, reducing costs, and simplifying logistics for robotics designers. The post Bal Seal offers pre-certified IP67, IP69 seals for robots appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586088",
      "title": "North American robot orders increase in Q3 2025, reports A3",
      "url": "https://www.therobotreport.com/north-american-robot-orders-increase-q3-2025-reports-a3/",
      "publishedAt": "Wed, 19 Nov 2025 17:55:06 +0000",
      "summary": "Q3 2025 orders in food and consumer packaged goods surpassed robot orders in automotive manufacturing, said A3. The post North American robot orders increase in Q3 2025, reports A3 appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586077",
      "title": "Encord releases EBIND multimodal embedding model for AI agents",
      "url": "https://www.therobotreport.com/encord-releases-ebind-multimodal-embedding-model-ai-agents/",
      "publishedAt": "Wed, 19 Nov 2025 14:59:22 +0000",
      "summary": "Encord said its EBIND model, based on the E-MM1 dataset, is scalable and resource-light, allowing for the use of multiple data sources. The post Encord releases EBIND multimodal embedding model for AI agents appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586078",
      "title": "6 trends shaping robotics and AI",
      "url": "https://www.therobotreport.com/6-trends-shaping-robotics-and-ai/",
      "publishedAt": "Wed, 19 Nov 2025 13:57:28 +0000",
      "summary": "MassRobotics survey offers a snapshot of current practices, challenges, and future expectations about sensor fusion, AI integration, motor control, power consumption, and safety and security. The post 6 trends shaping robotics and AI appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586071",
      "title": "Agile Robots launches Agile ONE industrial humanoid",
      "url": "https://www.therobotreport.com/agile-robots-launches-agile-one-industrial-humanoid/",
      "publishedAt": "Wed, 19 Nov 2025 06:28:37 +0000",
      "summary": "Agile Robots has developed the hardware and AI for Agile ONE in house and plans to manufacture the humanoid in Germany. The post Agile Robots launches Agile ONE industrial humanoid appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586052",
      "title": "Schneider Electric earns UL ECOLOGO certification for industrial automation",
      "url": "https://www.therobotreport.com/schneider-electric-earns-ul-ecologo-certification-industrial-automation/",
      "publishedAt": "Tue, 18 Nov 2025 23:30:11 +0000",
      "summary": "Schneider Electric has obtained UL sustainability certification for its industrial automation and energy equipment. The post Schneider Electric earns UL ECOLOGO certification for industrial automation appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586066",
      "title": "Zoox offers its first public autonomous rides in San Francisco",
      "url": "https://www.therobotreport.com/zoox-offers-first-public-autonomous-rides-san-francisco/",
      "publishedAt": "Tue, 18 Nov 2025 22:35:31 +0000",
      "summary": "Zoox is accepting its first public riders in San Francisco through its Explorer program, which gives riders early access. The post Zoox offers its first public autonomous rides in San Francisco appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://blogs.nvidia.com/?p=87636",
      "title": "Powering AI Superfactories, NVIDIA and Microsoft Integrate Latest Technologies for Inference, Cybersecurity, Physical AI",
      "url": "https://blogs.nvidia.com/blog/nvidia-microsoft-ai-superfactories/",
      "publishedAt": "Tue, 18 Nov 2025 20:00:22 +0000",
      "summary": "Timed with the Microsoft Ignite conference running this week, NVIDIA is expanding its collaboration with Microsoft, including through the adoption of next-generation NVIDIA Spectrum-X Ethernet switches for the new Microsoft Fairwater AI superfactory, powered by the NVIDIA Blackwell platform. The collaboration brings new integrations across Microsoft 365 Copilot, as well as the public preview of Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": []
    },
    {
      "id": "http://arxiv.org/abs/2511.14759v1",
      "title": "$Ï€^{*}_{0.6}$: a VLA That Learns From Experience",
      "url": "https://arxiv.org/abs/2511.14759v1",
      "publishedAt": "2025-11-18T18:58:55Z",
      "summary": "We study how vision-language-action (VLA) models can improve through real-world deployments via reinforcement learning (RL). We present a general-purpose method, RL with Experience and Corrections via Advantage-conditioned Policies (RECAP), that provides for RL training of VLAs via advantage conditioning.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "RL",
        "Vision"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14756v1",
      "title": "HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation",
      "url": "https://arxiv.org/abs/2511.14756v1",
      "publishedAt": "2025-11-18T18:56:24Z",
      "summary": "Learning from real-world robot demonstrations holds promise for interacting with complex real-world environments. However, the complexity and variability of interaction dynamics often cause purely positional controllers to struggle with contacts or varying payloads.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14755v1",
      "title": "Robust Verification of Controllers under State Uncertainty via Hamilton-Jacobi Reachability Analysis",
      "url": "https://arxiv.org/abs/2511.14755v1",
      "publishedAt": "2025-11-18T18:55:20Z",
      "summary": "As perception-based controllers for autonomous systems become increasingly popular in the real world, it is important that we can formally verify their safety and performance despite perceptual uncertainty. Unfortunately, the verification of such systems remains challenging, largely due to the complexity of the controllers, which are often nonlinear, nonconvex, learning-based, and/or black-box.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Vision"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14751v1",
      "title": "Co-Me: Confidence-Guided Token Merging for Visual Geometric Transformers",
      "url": "https://arxiv.org/abs/2511.14751v1",
      "publishedAt": "2025-11-18T18:52:22Z",
      "summary": "We propose Confidence-Guided Token Merging (Co-Me), an acceleration mechanism for visual geometric transformers without retraining or finetuning the base model. Co-Me distilled a light-weight confidence predictor to rank tokens by uncertainty and selectively merge low-confidence ones, effectively reducing computation while maintaining spatial coverage.",
      "source": "arXiv",
      "type": "paper",
      "tags": []
    },
    {
      "id": "https://www.therobotreport.com/?p=586059",
      "title": "Waymo launching driverless robotaxis in 5 more cities",
      "url": "https://www.therobotreport.com/waymo-launching-driverless-robotaxis-in-5-more-cities/",
      "publishedAt": "Tue, 18 Nov 2025 17:56:22 +0000",
      "summary": "Waymo said it has entered a new phase of commercial scale, doubling the number of cities it operates in without a human specialist in the car. The post Waymo launching driverless robotaxis in 5 more cities appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586058",
      "title": "Distalmotion raises $150M to accelerate U.S. adoption of DEXTER surgical robot",
      "url": "https://www.therobotreport.com/distalmotion-raises-150m-accelerate-u-s-dexter-surgical-robot-adoption/",
      "publishedAt": "Tue, 18 Nov 2025 17:49:28 +0000",
      "summary": "Distalmotion plans to use the funding to target the U.S. ambulatory surgery center market for its DEXTER robot. The post Distalmotion raises $150M to accelerate U.S. adoption of DEXTER surgical robot appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14659v1",
      "title": "NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards",
      "url": "https://arxiv.org/abs/2511.14659v1",
      "publishedAt": "2025-11-18T16:55:48Z",
      "summary": "Vision--language--action (VLA) models have recently shown promising performance on a variety of embodied tasks, yet they still fall short in reliability and generalization, especially when deployed across different embodiments or real-world environments. In this work, we introduce NORA-1.5, a VLA model built from the pre-trained NORA backbone by adding to it a flow-matching-based action expert.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Embodied AI",
        "Vision"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14625v1",
      "title": "Gallant: Voxel Grid-based Humanoid Locomotion and Local-navigation across 3D Constrained Terrains",
      "url": "https://arxiv.org/abs/2511.14625v1",
      "publishedAt": "2025-11-18T16:16:31Z",
      "summary": "Robust humanoid locomotion requires accurate and globally consistent perception of the surrounding 3D environment. However, existing perception modules, mainly based on depth images or elevation maps, offer only partial and locally flattened views of the environment, failing to capture the full 3D structure.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Vision"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14624v1",
      "title": "Active Matter as a framework for living systems-inspired Robophysics",
      "url": "https://arxiv.org/abs/2511.14624v1",
      "publishedAt": "2025-11-18T16:16:27Z",
      "summary": "Robophysics investigates the physical principles that govern living-like robots operating in complex, realworld environments. Despite remarkable technological advances, robots continue to face fundamental efficiency limitations.",
      "source": "arXiv",
      "type": "paper",
      "tags": []
    },
    {
      "id": "http://arxiv.org/abs/2511.14592v1",
      "title": "Is Your VLM for Autonomous Driving Safety-Ready? A Comprehensive Benchmark for Evaluating External and In-Cabin Risks",
      "url": "https://arxiv.org/abs/2511.14592v1",
      "publishedAt": "2025-11-18T15:33:49Z",
      "summary": "Vision-Language Models (VLMs) show great promise for autonomous driving, but their suitability for safety-critical scenarios is largely unexplored, raising safety concerns. This issue arises from the lack of comprehensive benchmarks that assess both external environmental risks and in-cabin driving behavior safety simultaneously.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Autonomous Driving",
        "Vision"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14565v1",
      "title": "Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language",
      "url": "https://arxiv.org/abs/2511.14565v1",
      "publishedAt": "2025-11-18T15:07:50Z",
      "summary": "Robots can adapt to user preferences by learning reward functions from demonstrations, but with limited data, reward models often overfit to spurious correlations and fail to generalize. This happens because demonstrations show robots how to do a task but not what matters for that task, causing the model to focus on irrelevant state details.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "LLM"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14533v1",
      "title": "A Neuro-Symbolic Framework for Reasoning under Perceptual Uncertainty: Bridging Continuous Perception and Discrete Symbolic Planning",
      "url": "https://arxiv.org/abs/2511.14533v1",
      "publishedAt": "2025-11-18T14:38:01Z",
      "summary": "Bridging continuous perceptual signals and discrete symbolic reasoning is a fundamental challenge in AI systems that must operate under uncertainty. We present a neuro-symbolic framework that explicitly models and propagates uncertainty from perception to planning, providing a principled connection between these two abstraction levels.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Vision",
        "Planning"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586055",
      "title": "1HMX introduces Nexus NX1 for full-body motion capture, teleoperation",
      "url": "https://www.therobotreport.com/1hmx-introduces-nexus-nx1-for-full-body-motion-capture-teleoperation/",
      "publishedAt": "Tue, 18 Nov 2025 14:00:11 +0000",
      "summary": "The Nexus NX1 system from 1HMX enables teleoperation and training of humanoid robots, realistic virtual reality, and simulation. The post 1HMX introduces Nexus NX1 for full-body motion capture, teleoperation appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14504v1",
      "title": "Aerial Assistance System for Automated Firefighting during Turntable Ladder Operations",
      "url": "https://arxiv.org/abs/2511.14504v1",
      "publishedAt": "2025-11-18T13:48:40Z",
      "summary": "Fires in industrial facilities pose special challenges to firefighters, e.g., due to the sheer size and scale of the buildings. The resulting visual obstructions impair firefighting accuracy, further compounded by inaccurate assessments of the fire's location. Such imprecision simultaneously increases the overall damage and prolongs the fire-brigades operation unnecessarily.",
      "source": "arXiv",
      "type": "paper",
      "tags": []
    },
    {
      "id": "http://arxiv.org/abs/2511.14499v1",
      "title": "Enhancing End-to-End Autonomous Driving with Risk Semantic Distillaion from VLM",
      "url": "https://arxiv.org/abs/2511.14499v1",
      "publishedAt": "2025-11-18T13:46:18Z",
      "summary": "The autonomous driving (AD) system has exhibited remarkable performance in complex driving scenarios. However, generalization is still a key limitation for the current system, which refers to the ability to handle unseen scenarios or unfamiliar sensor configurations.Related works have explored the use of Vision-Language Models (VLMs) to address few-shot or zero-shot tasks.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Autonomous Driving",
        "Vision"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14469v1",
      "title": "CompEvent: Complex-valued Event-RGB Fusion for Low-light Video Enhancement and Deblurring",
      "url": "https://arxiv.org/abs/2511.14469v1",
      "publishedAt": "2025-11-18T13:09:13Z",
      "summary": "Low-light video deblurring poses significant challenges in applications like nighttime surveillance and autonomous driving due to dim lighting and long exposures. While event cameras offer potential solutions with superior low-light sensitivity and high temporal resolution, existing fusion methods typically employ staged strategies, limiting their effectiveness against combined low-light and motion blur degradations.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Autonomous Driving"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14458v1",
      "title": "Advancing Minimally Invasive Precision Surgery in Open Cavities with Robotic Flexible Endoscopy",
      "url": "https://arxiv.org/abs/2511.14458v1",
      "publishedAt": "2025-11-18T13:01:05Z",
      "summary": "Flexible robots hold great promise for enhancing minimally invasive surgery (MIS) by providing superior dexterity, precise control, and safe tissue interaction. Yet, translating these advantages into endoscopic interventions within open cavities remains challenging.",
      "source": "arXiv",
      "type": "paper",
      "tags": []
    },
    {
      "id": "http://arxiv.org/abs/2511.14438v1",
      "title": "Towards A Catalogue of Requirement Patterns for Space Robotic Missions",
      "url": "https://arxiv.org/abs/2511.14438v1",
      "publishedAt": "2025-11-18T12:35:49Z",
      "summary": "In the development of safety and mission-critical systems, including autonomous space robotic missions, complex behaviour is captured during the requirements elicitation phase. Requirements are typically expressed using natural language which is ambiguous and not amenable to formal verification methods that can provide robust guarantees of system behaviour.",
      "source": "arXiv",
      "type": "paper",
      "tags": []
    },
    {
      "id": "http://arxiv.org/abs/2511.14434v1",
      "title": "Achieving Safe Control Online through Integration of Harmonic Control Lyapunov-Barrier Functions with Unsafe Object-Centric Action Policies",
      "url": "https://arxiv.org/abs/2511.14434v1",
      "publishedAt": "2025-11-18T12:34:48Z",
      "summary": "We propose a method for combining Harmonic Control Lyapunov-Barrier Functions (HCLBFs) derived from Signal Temporal Logic (STL) specifications with any given robot policy to turn an unsafe policy into a safe one with formal guarantees. The two components are combined via HCLBF-derived safety certificates, thus producing commands that preserve both safety and task-driven behavior.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14433v1",
      "title": "Safe-ROS: An Architecture for Autonomous Robots in Safety-Critical Domains",
      "url": "https://arxiv.org/abs/2511.14433v1",
      "publishedAt": "2025-11-18T12:34:33Z",
      "summary": "Deploying autonomous robots in safety-critical domains requires architectures that ensure operational effectiveness and safety compliance. In this paper, we contribute the Safe-ROS architecture for developing reliable and verifiable autonomous robots in such domains.",
      "source": "arXiv",
      "type": "paper",
      "tags": []
    },
    {
      "id": "http://arxiv.org/abs/2511.14432v1",
      "title": "Mutation Testing for Industrial Robotic Systems",
      "url": "https://arxiv.org/abs/2511.14432v1",
      "publishedAt": "2025-11-18T12:34:19Z",
      "summary": "Industrial robotic systems (IRS) are increasingly deployed in diverse environments, where failures can result in severe accidents and costly downtime. Ensuring the reliability of the software controlling these systems is therefore critical. Mutation testing, a technique widely used in software engineering, evaluates the effectiveness of test suites by introducing small faults, or mutants, into the code.",
      "source": "arXiv",
      "type": "paper",
      "tags": []
    },
    {
      "id": "http://arxiv.org/abs/2511.14428v1",
      "title": "Context-aware, Ante-hoc Explanations of Driving Behaviour",
      "url": "https://arxiv.org/abs/2511.14428v1",
      "publishedAt": "2025-11-18T12:33:24Z",
      "summary": "Autonomous vehicles (AVs) must be both safe and trustworthy to gain social acceptance and become a viable option for everyday public transportation. Explanations about the system behaviour can increase safety and trust in AVs. Unfortunately, explaining the system behaviour of AI-based driving functions is particularly challenging, as decision-making processes are often opaque.",
      "source": "arXiv",
      "type": "paper",
      "tags": []
    },
    {
      "id": "http://arxiv.org/abs/2511.14427v1",
      "title": "Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning",
      "url": "https://arxiv.org/abs/2511.14427v1",
      "publishedAt": "2025-11-18T12:32:23Z",
      "summary": "Effective contact-rich manipulation requires robots to synergistically leverage vision, force, and proprioception. However, Reinforcement Learning agents struggle to learn in such multisensory settings, especially amidst sensory noise and dynamic changes. We propose MultiSensory Dynamic Pretraining (MSDP), a novel framework for learning expressive multisensory representations tailored for task-oriented policy learning.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Robotics",
        "RL",
        "Vision"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14396v1",
      "title": "Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning",
      "url": "https://arxiv.org/abs/2511.14396v1",
      "publishedAt": "2025-11-18T12:01:06Z",
      "summary": "Language-conditioned manipulation facilitates human-robot interaction via behavioral cloning (BC), which learns control policies from human demonstrations and serves as a cornerstone of embodied AI. Overcoming compounding errors in sequential action decisions remains a central challenge to improving BC performance.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Robotics",
        "Embodied AI",
        "Vision"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.14393v1",
      "title": "Perception-aware Exploration for Consumer-grade UAVs",
      "url": "https://arxiv.org/abs/2511.14393v1",
      "publishedAt": "2025-11-18T11:55:04Z",
      "summary": "In our work, we extend the current state-of-the-art approach for autonomous multi-UAV exploration to consumer-level UAVs, such as the DJI Mini 3 Pro. We propose a pipeline that selects viewpoint pairs from which the depth can be estimated and plans the trajectory that satisfies motion constraints necessary for odometry estimation.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Vision"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586049",
      "title": "The 2026 Charging Playbook",
      "url": "https://www.therobotreport.com/the-2026-charging-playbook/",
      "publishedAt": "Mon, 17 Nov 2025 21:04:40 +0000",
      "summary": "Autonomous and collaborative robots, like AMRs and AGVs, are now driving flexible automation in manufacturing and logistics. Download the eBook to learn more. The post The 2026 Charging Playbook appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586039",
      "title": "Teradar emerges from stealth with terahertz vision sensor, Series B funding",
      "url": "https://www.therobotreport.com/teradar-emerges-stealth-terahertz-vision-sensor-series-b-funding/",
      "publishedAt": "Mon, 17 Nov 2025 17:08:28 +0000",
      "summary": "Teradar claimed its terahertz chip technology is superior to lidar and radar for all-weather vision for autonomous vehicles. The post Teradar emerges from stealth with terahertz vision sensor, Series B funding appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics",
        "Vision"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586042",
      "title": "French startup Exwayz raises â‚¬1M to develop SLAM software",
      "url": "https://www.therobotreport.com/french-startup-exwayz-raises-e1m-develops-slam-software/",
      "publishedAt": "Mon, 17 Nov 2025 08:00:37 +0000",
      "summary": "Exwayz raised funding for its 3D SLAM navigation software for autonomous systems and has partnered with Embotech and Cyvl.ai. The post French startup Exwayz raises â‚¬1M to develop SLAM software appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics",
        "Planning"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586022",
      "title": "Micropolis builds the future of robotics in Dubai",
      "url": "https://www.therobotreport.com/micropolis-builds-future-robotics-dubai/",
      "publishedAt": "Sun, 16 Nov 2025 13:38:37 +0000",
      "summary": "Fareed Aljawhari shares his journey from creative director to robotics CEO, focusing on smart cities with Micropolis. The post Micropolis builds the future of robotics in Dubai appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.12590v2",
      "title": "Fine-Grained Representation for Lane Topology Reasoning",
      "url": "https://arxiv.org/abs/2511.12590v2",
      "publishedAt": "2025-11-16T13:24:30Z",
      "summary": "Precise modeling of lane topology is essential for autonomous driving, as it directly impacts navigation and control decisions. Existing methods typically represent each lane with a single query and infer topological connectivity based on the similarity between lane queries. However, this kind of design struggles to accurately model complex lane structures, leading to unreliable topology prediction.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Autonomous Driving"
      ]
    },
    {
      "id": "https://www.therobotreport.com/?p=586036",
      "title": "Beyond the robot: Shaping the future of autonomous operations",
      "url": "https://www.therobotreport.com/beyond-robot-shaping-future-autonomous-operations/",
      "publishedAt": "Sat, 15 Nov 2025 22:02:32 +0000",
      "summary": "Autonomous inspections demonstrate how industry is moving past sensing and data to operational intelligence, says ANYbotics' CEO. The post Beyond the robot: Shaping the future of autonomous operations appeared first on The Robot Report .",
      "source": "The Robot Report",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://blogs.nvidia.com/?p=87325",
      "title": "AI On: 3 Ways to Bring Agentic AI to Computer Vision Applications",
      "url": "https://blogs.nvidia.com/blog/ways-to-bring-agentic-ai-to-computer-vision-applications/",
      "publishedAt": "Thu, 13 Nov 2025 18:50:06 +0000",
      "summary": "Editorâ€™s note: This post is part of the AI On blog series, which explores the latest techniques and real-world applications of agentic AI, chatbots and copilots. The series also highlights the NVIDIA software and hardware powering advanced AI agents, which form the foundation of AI query engines that gather insights and perform tasks to transform Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Vision"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2511.10701v2",
      "title": "CARScenes: Semantic VLM Dataset for Safe Autonomous Driving",
      "url": "https://arxiv.org/abs/2511.10701v2",
      "publishedAt": "2025-11-12T21:13:19Z",
      "summary": "CAR-Scenes is a frame-level dataset for autonomous driving that enables training and evaluation of vision-language models (VLMs) for interpretable, scene-level understanding.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Autonomous Driving",
        "Vision"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3066690",
      "title": "WhyÂ a researcherÂ is building robots that look and act like bats",
      "url": "https://techcrunch.com/2025/11/12/why-a-researcher-is-building-robots-that-look-and-act-like-bats/",
      "publishedAt": "Wed, 12 Nov 2025 17:12:07 +0000",
      "summary": "These palm-sized robots use ultrasound signals to navigate harsh conditions in search and rescue missions.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": []
    },
    {
      "id": "https://techcrunch.com/?p=3064348",
      "title": "AI researchers &#8217;embodied&#8217; an LLM into a robot â€“ and it started channeling Robin Williams",
      "url": "https://techcrunch.com/2025/11/01/ai-researchers-embodied-an-llm-into-a-robot-and-it-started-channeling-robin-williams/",
      "publishedAt": "Sat, 01 Nov 2025 15:00:00 +0000",
      "summary": "AI researchers at Andon Labs embedded various LLMs in a vacuum robot to test how ready they were to be embodied. And hilarity ensued.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics",
        "Embodied AI",
        "LLM"
      ]
    },
    {
      "id": "https://blogs.nvidia.com/?p=86672",
      "title": "Into the Omniverse: Open World Foundation Models Generate Synthetic Worlds for Physical AI Development",
      "url": "https://blogs.nvidia.com/blog/scaling-physical-ai-omniverse/",
      "publishedAt": "Wed, 29 Oct 2025 13:00:30 +0000",
      "summary": "Physical AI models â€” which power robots, autonomous vehicles and other intelligent machines â€” must be safe, generalized for dynamic scenarios and capable of perceiving, reasoning and operating in real time.",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": []
    },
    {
      "id": "https://blogs.nvidia.com/?p=86223",
      "title": "NVIDIA GTC Washington, DC: Live Updates on Whatâ€™s Next in AI",
      "url": "https://blogs.nvidia.com/blog/nvidia-gtc-washington-dc-2025-news/",
      "publishedAt": "Tue, 28 Oct 2025 19:45:40 +0000",
      "summary": "Monday, Oct. 27, 12:30 p.m. ET How Medium-Sized Cities Are Tackling AI Readiness ðŸ”— A panel discussion today at GTC Washington, D.C., highlighted a public-private initiative to invigorate the economy of Rancho Cordova, California, with a focus on AI. To bolster innovation, the city is working with the Human Machine Collaboration Institute and NVIDIA on Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": []
    },
    {
      "id": "https://blogs.nvidia.com/?p=86513",
      "title": "Fueling Economic Development Across the US: How NVIDIA Is Empowering States, Municipalities and Universities to Drive Innovation",
      "url": "https://blogs.nvidia.com/blog/economic-development-us/",
      "publishedAt": "Tue, 28 Oct 2025 18:02:21 +0000",
      "summary": "To democratize access to AI technology nationwide, AI education and deployment canâ€™t be limited to a few urban tech hubs â€” it must reach every community, university and state. Thatâ€™s why NVIDIA is working with cities, states and educational institutions to embed AI education and innovation across the U.S., with the goal of helping the Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": []
    },
    {
      "id": "https://blogs.nvidia.com/?p=86374",
      "title": "NVIDIA IGX Thor Robotics Processor Brings Real-Time Physical AI to the Industrial and Medical Edge",
      "url": "https://blogs.nvidia.com/blog/igx-thor-processor-physical-ai-industrial-medical-edge/",
      "publishedAt": "Tue, 28 Oct 2025 17:58:53 +0000",
      "summary": "AI is moving from the digital world into the physical one. Across factory floors and operating rooms, machines are evolving into collaborators that can see, sense and make decisions in real time. To accelerate this transformation, NVIDIA today unveiled NVIDIA IGX Thor, a powerful, industrial-grade platform built to bring real-time physical AI directly to the edge, Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://blogs.nvidia.com/?p=86476",
      "title": "NVIDIA Launches Open Models and Data to Accelerate AI Innovation Across Language, Biology and Robotics",
      "url": "https://blogs.nvidia.com/blog/open-models-data-ai/",
      "publishedAt": "Tue, 28 Oct 2025 17:31:14 +0000",
      "summary": "Furthering its deep commitment to open source, NVIDIA is unveiling new open-source AI technologies for language, robotics and biology â€” contributing to an open ecosystem that broadens access to AI and fuels U.S. innovation. These open technologies will empower developers worldwide and strengthen economic growth through efficient reasoning, high-fidelity world generation and interactive physical AI Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2510.23129v2",
      "title": "Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots",
      "url": "https://arxiv.org/abs/2510.23129v2",
      "publishedAt": "2025-10-27T09:05:27Z",
      "summary": "The deployment of mobile robots for material handling in industrial environments requires scalable coordination of large fleets in dynamic settings. This paper presents a two-layer framework that combines high-level scheduling with low-level control. Tasks are assigned and scheduled using the compositional algorithm ComSat, which generates time-parameterized routes for each robot.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://blogs.nvidia.com/?p=86265",
      "title": "NVIDIA Contributes to Open Frameworks for Next-Generation Robotics Development",
      "url": "https://blogs.nvidia.com/blog/roscon-2025-open-framework-robotics/",
      "publishedAt": "Mon, 27 Oct 2025 00:00:55 +0000",
      "summary": "This yearâ€™s ROSCon conference heads to Singapore, bringing together the global robotics developer community behind Robot Operating System (ROS) â€” the worldâ€™s most widely adopted open framework for building robots. At the conference, running through Wednesday, Oct. 29, NVIDIA announced collaborations with partners and the Open Source Robotics Alliance (OSRA), as well as new robotics Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2510.18544v3",
      "title": "SLICE: SLO-Driven Scheduling for LLM Inference on Edge Computing Devices",
      "url": "https://arxiv.org/abs/2510.18544v3",
      "publishedAt": "2025-10-21T11:47:42Z",
      "summary": "Large Language Models (LLMs), as the foundational architecture for next-generation interactive AI applications, not only power intelligent dialogue systems but also drive the evolution of embodied intelligence on edge devices, including humanoid robots, smart vehicles, and other scenarios.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Embodied AI",
        "LLM"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3057128",
      "title": "CocoÂ RoboticsÂ taps UCLA professor to lead new physical AI research lab",
      "url": "https://techcrunch.com/2025/10/14/coco-robotics-taps-ucla-professor-to-lead-new-physical-ai-research-lab/",
      "publishedAt": "Tue, 14 Oct 2025 15:51:10 +0000",
      "summary": "Coco Robotics is working toward automating its fleet of delivery robots using its millions of miles of collected data.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3056108",
      "title": "The world is justÂ not quite readyÂ for humanoids yet",
      "url": "https://techcrunch.com/2025/10/10/the-world-is-just-not-quite-ready-for-humanoids-yet/",
      "publishedAt": "Fri, 10 Oct 2025 13:15:00 +0000",
      "summary": "Despite the amount of money being injected into the industry, humanoids won't be able to learn dexterity -- or the fine motor movements with hands -- rendering them essentially useless.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": []
    },
    {
      "id": "https://techcrunch.com/?p=3055392",
      "title": "SoftBank bulks up its robotics portfolioÂ withÂ ABB Groupâ€™s robotics unit",
      "url": "https://techcrunch.com/2025/10/08/softbank-bulks-up-its-robotics-portfolio-with-abb-groups-robotics-unit/",
      "publishedAt": "Wed, 08 Oct 2025 14:10:18 +0000",
      "summary": "SoftBank says this acquisition will help it dive deeper into robotics as it considers physical AI to be the next frontier.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3052476",
      "title": "Former OpenAI and DeepMind researchers raise whopping $300M seed to automate science",
      "url": "https://techcrunch.com/2025/09/30/former-openai-and-deepmind-researchers-raise-whopping-300m-seed-to-automate-science/",
      "publishedAt": "Tue, 30 Sep 2025 18:56:59 +0000",
      "summary": "Periodic Labs has raised from a tech industry who's who, including Andreessen Horowitz, Nvidia, Elad Gil, Jeff Dean, Eric Schmidt, and Jeff Bezos.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": []
    },
    {
      "id": "https://blogs.nvidia.com/?p=85387",
      "title": "Into the Omniverse: Open-Source Physics Engine and OpenUSD Advance Robot Learning",
      "url": "https://blogs.nvidia.com/blog/newton-physics-engine-openusd/",
      "publishedAt": "Tue, 30 Sep 2025 13:00:07 +0000",
      "summary": "Building robots that can effectively operate alongside human workers in factories, hospitals and public spaces presents an enormous technical challenge. These robots require humanlike dexterity, perception, cognition and whole-body coordination to navigate unpredictable real-world environments in real time.",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Robotics",
        "Vision"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2509.17812v2",
      "title": "Tac2Motion: Contact-Aware Reinforcement Learning with Tactile Feedback for Robotic Hand Manipulation",
      "url": "https://arxiv.org/abs/2509.17812v2",
      "publishedAt": "2025-09-22T14:05:59Z",
      "summary": "This paper proposes Tac2Motion, a contact-aware reinforcement learning framework to facilitate the learning of contact-rich in-hand manipulation tasks, such as removing a lid. To this end, we propose tactile sensing-based reward shaping and incorporate the sensing into the observation space through embedding.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "RL"
      ]
    },
    {
      "id": "https://techcrunch.com/?post_type=tc_podcast&#038;p=3047793",
      "title": "Live demo fails, AI safety wins, and the golden age of robotics",
      "url": "https://techcrunch.com/podcast/live-demo-fails-ai-safety-wins-and-the-golden-age-of-robotics/",
      "publishedAt": "Fri, 19 Sep 2025 15:48:52 +0000",
      "summary": "This week on Equity, Anthony Ha, Kirsten Korosec, and Max Zeff unpack the biggest moves in AI, robotics, and regulation. Listen to the full episode to hear about: Equity will be back next week. Subscribe wherever you get your podcasts! Equity is TechCrunchâ€™s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday. [&#8230;]",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2509.07463v2",
      "title": "DepthVision: Enabling Robust Vision-Language Models with GAN-Based LiDAR-to-RGB Synthesis for Autonomous Driving",
      "url": "https://arxiv.org/abs/2509.07463v2",
      "publishedAt": "2025-09-09T07:42:07Z",
      "summary": "Ensuring reliable autonomous operation when visual input is degraded remains a key challenge in intelligent vehicles and robotics. We present DepthVision, a multimodal framework that enables Vision--Language Models (VLMs) to exploit LiDAR data without any architectural changes or retraining.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Autonomous Driving",
        "Robotics",
        "Vision"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3038948",
      "title": "Why Runway is eyeing the robotics industry for future revenue growth",
      "url": "https://techcrunch.com/2025/09/01/why-runway-is-eyeing-the-robotics-industry-for-future-revenue-growth/",
      "publishedAt": "Mon, 01 Sep 2025 15:00:00 +0000",
      "summary": "Runway is building up a robotics-focused team and fine-tuning its existing models for robotics and self-driving car customers.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Autonomous Driving",
        "Robotics"
      ]
    },
    {
      "id": "https://blogs.nvidia.com/?p=84322",
      "title": "How Do You Teach an AI Model to Reason? With Humans",
      "url": "https://blogs.nvidia.com/blog/ai-reasoning-cosmos/",
      "publishedAt": "Wed, 27 Aug 2025 23:13:16 +0000",
      "summary": "AI models are advancing at a rapid rate and scale. But what might they lack that (most) humans donâ€™t? Common sense: an understanding, developed through real-world experiences, that birds canâ€™t fly backwards, mirrors are reflective and ice melts into water. While such principles seem obvious to humans, they must be taught to AI models tasked Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": []
    },
    {
      "id": "https://blogs.nvidia.com/?p=84194",
      "title": "NVIDIA Jetson Thor Unlocks Real-Time Reasoning for General Robotics and Physical AI",
      "url": "https://blogs.nvidia.com/blog/jetson-thor-physical-ai-edge/",
      "publishedAt": "Mon, 25 Aug 2025 15:00:31 +0000",
      "summary": "Robots around the world are about to get a lot smarter as physical AI developers plug in NVIDIA Jetson Thor modules â€” new robotics computers that can serve as the brains for robotic systems across research and industry. Robots demand rich sensor data and low-latency AI processing. Running real-time robotic applications requires significant AI compute Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2508.14160v2",
      "title": "RynnEC: Bringing MLLMs into Embodied World",
      "url": "https://arxiv.org/abs/2508.14160v2",
      "publishedAt": "2025-08-19T18:00:01Z",
      "summary": "We introduce RynnEC, a video multimodal large language model designed for embodied cognition. Built upon a general-purpose vision-language foundation model, RynnEC incorporates a region encoder and a mask decoder, enabling flexible region-level video interaction. Despite its compact architecture, RynnEC achieves state-of-the-art performance in object property understanding, object segmentation, and spatial reasoning.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Embodied AI",
        "LLM",
        "Vision"
      ]
    },
    {
      "id": "https://blogs.nvidia.com/?p=83816",
      "title": "Celebrating More Than 2 Million Developers Embracing NVIDIA Robotics",
      "url": "https://blogs.nvidia.com/blog/2-million-robotics-developers/",
      "publishedAt": "Mon, 18 Aug 2025 16:00:34 +0000",
      "summary": "Weâ€™re celebrating the more than 2 million developers now using the NVIDIA robotics stack. These builders are reshaping industries across manufacturing, food delivery, agriculture, healthcare, facilities maintenance and much more.",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://blogs.nvidia.com/?p=83562",
      "title": "Making Safer Spaces: NVIDIA and Partners Bring Physical AI to Cities and Industrial Infrastructure",
      "url": "https://blogs.nvidia.com/blog/physical-ai-partners-metropolis-updates-siggraph/",
      "publishedAt": "Mon, 11 Aug 2025 15:00:44 +0000",
      "summary": "Physical AI is becoming the foundation of smart cities, facilities and industrial processes across the globe. NVIDIA is working with companies including Accenture, Avathon, Belden, DeepHow, Milestone Systems and Telit Cinterion to enhance operations across the globe with physical AI-based perception and reasoning. The continuous loop of simulating, training and deploying physical AI offers sophisticated Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Vision"
      ]
    },
    {
      "id": "https://blogs.nvidia.com/?p=83581",
      "title": "Amazon Devices &#038; Services Achieves Major Step Toward Zero-Touch Manufacturing With NVIDIA AI and Digital Twins",
      "url": "https://blogs.nvidia.com/blog/amazon-zero-touch-manufacturing/",
      "publishedAt": "Mon, 11 Aug 2025 15:00:00 +0000",
      "summary": "Using NVIDIA digital twin technologies, Amazon Devices &#38; Services is powering big leaps in manufacturing with a new physical AI software solution. Deployed this month at an Amazon Devices facility, the companyâ€™s innovative, simulation-first approach for zero-touch manufacturing trains robotic arms to inspect diverse devices for product-quality auditing and integrate new goods into the production Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": []
    },
    {
      "id": "https://blogs.nvidia.com/?p=74901",
      "title": "What Is NVIDIAâ€™s Three-Computer Solution for Robotics?",
      "url": "https://blogs.nvidia.com/blog/three-computers-robotics/",
      "publishedAt": "Fri, 08 Aug 2025 16:00:13 +0000",
      "summary": "Physical AI â€” the embodiment of artificial intelligence in robots, visual AI agents, warehouses and factories and other autonomous systems that operate in the real world â€” is experiencing its breakthrough moment.",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3031231",
      "title": "Tesla is reportedly behind on its pledge to build 5,000 Optimus bots this year",
      "url": "https://techcrunch.com/2025/07/25/tesla-is-reportedly-behind-on-its-pledge-to-build-5000-optimus-bots-this-year/",
      "publishedAt": "Fri, 25 Jul 2025 14:14:19 +0000",
      "summary": "Tesla is behind on its goal to produce at least 5,000 Optimus humanoid robots by the end of 2025.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": []
    },
    {
      "id": "https://techcrunch.com/?p=3030126",
      "title": "How TRIC Robotics is reducing pesticide use on strawberries using UV light",
      "url": "https://techcrunch.com/2025/07/23/how-tric-robotics-is-reducing-pesticide-use-on-strawberries-using-uv-light/",
      "publishedAt": "Wed, 23 Jul 2025 14:00:00 +0000",
      "summary": "TRIC Robotics just raised a $5.5 million seed round for its tractor-sized robots that help eliminate bacteria and pests on strawberry plants.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3026176",
      "title": "Diligent Robotics hires two notable Cruise alumni to its leadership team",
      "url": "https://techcrunch.com/2025/07/10/diligent-robotics-adds-two-notable-cruise-alumni-to-its-leadership-team/",
      "publishedAt": "Thu, 10 Jul 2025 13:00:00 +0000",
      "summary": "Diligent Robotics hired Cruise's former chief operating officer and former head of AI and robotics into c-suite positions.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3025792",
      "title": "Hugging Face opens up orders for its Reachy Mini desktop robots",
      "url": "https://techcrunch.com/2025/07/09/hugging-face-opens-up-orders-for-its-reachy-mini-desktop-robots/",
      "publishedAt": "Wed, 09 Jul 2025 07:00:00 +0000",
      "summary": "Hugging Face is releasing two versions of its desktop robot meant for designing and coding AI applications.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2506.23982v3",
      "title": "StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving",
      "url": "https://arxiv.org/abs/2506.23982v3",
      "publishedAt": "2025-06-30T15:48:38Z",
      "summary": "Personalization, while extensively studied in conventional autonomous driving pipelines, has been largely overlooked in the context of end-to-end autonomous driving (E2EAD), despite its critical role in fostering user trust, safety perception, and real-world adoption.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Autonomous Driving",
        "Vision"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2506.22242v2",
      "title": "4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration",
      "url": "https://arxiv.org/abs/2506.22242v2",
      "publishedAt": "2025-06-27T14:09:29Z",
      "summary": "Leveraging diverse robotic data for pretraining remains a critical challenge. Existing methods typically model the dataset's action distribution using simple observations as inputs. However, these inputs are often incomplete, resulting in a dispersed conditional action distribution-an issue we refer to as coordinate system chaos and state chaos. This inconsistency significantly hampers pretraining efficiency.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Vision"
      ]
    },
    {
      "id": "https://blogs.nvidia.com/?p=82559",
      "title": "NVIDIA and Partners Highlight Next-Generation Robotics, Automation and AI Technologies at Automatica",
      "url": "https://blogs.nvidia.com/blog/automatica-robotics-2025/",
      "publishedAt": "Tue, 24 Jun 2025 09:00:30 +0000",
      "summary": "From the heart of Germanyâ€™s automotive sector to manufacturing hubs across France and Italy, Europe is embracing industrial AI and advanced AI-powered robotics to address labor shortages, boost productivity and fuel sustainable economic growth. Robotics companies are developing humanoid robots and collaborative systems that integrate AI into real-world manufacturing applications.",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3020586",
      "title": "SoftBank reportedly looking to launch a trillion-dollar AI and robotics industrial complex",
      "url": "https://techcrunch.com/2025/06/20/softbank-reportedly-looking-to-launch-a-trillion-dollar-ai-and-robotics-industrial-complex/",
      "publishedAt": "Fri, 20 Jun 2025 15:22:06 +0000",
      "summary": "The investing conglomerate is looking to team up with TSMC on the initiative as SoftBank continues to pour money into AI.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://blogs.nvidia.com/?p=82396",
      "title": "Hexagon Taps NVIDIA Robotics and AI Software to Build and Deploy AEON, a New Humanoid",
      "url": "https://blogs.nvidia.com/blog/hexagon-robotics-ai-software-aeon-humanoid/",
      "publishedAt": "Tue, 17 Jun 2025 15:10:55 +0000",
      "summary": "As a global labor shortage leaves 50 million positions unfilled across industries like manufacturing and logistics, Hexagon â€” a global leader in measurement technologies â€” is developing humanoid robots that can lend a helping hand. Industrial sectors depend on skilled workers to perform a variety of error-prone tasks, including operating high-precision scanners for reality capture Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2506.14249v2",
      "title": "Robust Adaptive Time-Varying Control Barrier Function with Application to Robotic Surface Treatment",
      "url": "https://arxiv.org/abs/2506.14249v2",
      "publishedAt": "2025-06-17T07:11:03Z",
      "summary": "Set invariance techniques such as control barrier functions (CBFs) can be used to enforce time-varying constraints such as keeping a safe distance from dynamic objects. However, existing methods for enforcing time-varying constraints often overlook model uncertainties.",
      "source": "arXiv",
      "type": "paper",
      "tags": []
    },
    {
      "id": "https://techcrunch.com/?p=3018019",
      "title": "Sam Altman-backed Coco Robotics raises $80M",
      "url": "https://techcrunch.com/2025/06/11/sam-altman-backed-coco-robotics-raises-80m/",
      "publishedAt": "Wed, 11 Jun 2025 20:40:15 +0000",
      "summary": "Coco Robotics has made more than 500,000 deliveries with its zero-emissions robots since they hit the streets in 2020.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3017761",
      "title": "Meta&#8217;s V-JEPA 2 model teaches AI to understand its surroundings",
      "url": "https://techcrunch.com/2025/06/11/metas-v-jepa-2-model-teaches-ai-to-understand-its-surroundings/",
      "publishedAt": "Wed, 11 Jun 2025 15:54:09 +0000",
      "summary": "Meta's V-JEPA 2 model is a \"world model,\" referring to AI that is designed to understand its physical surroundings.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": []
    },
    {
      "id": "https://blogs.nvidia.com/?p=82037",
      "title": "European Robot Makers Adopt NVIDIA Isaac, Omniverse and Halos to Develop Safe, Physical AI-Driven Robot Fleets",
      "url": "https://blogs.nvidia.com/blog/european-robot-makers-isaac-omniverse-halos-safe-physical-ai/",
      "publishedAt": "Wed, 11 Jun 2025 11:00:23 +0000",
      "summary": "In the face of growing labor shortages and need for sustainability, European manufacturers are racing to reinvent their processes to become software-defined and AI-driven. To achieve this, robot developers and industrial digitalization solution providers are working with NVIDIA to build safe, AI-driven robots and industrial technologies to drive modern, sustainable manufacturing. At NVIDIA GTC Paris Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://blogs.nvidia.com/?p=82173",
      "title": "Germany Builds Its AI Autobahn With NVIDIA",
      "url": "https://blogs.nvidia.com/blog/germany-ai-factories/",
      "publishedAt": "Wed, 11 Jun 2025 10:25:33 +0000",
      "summary": "Germany is building on a long history of engineering innovation with new AI investments poised to transform the countryâ€™s economy â€” including the automotive, banking, manufacturing and robotics industries. The country is deploying tens of thousands of NVIDIA GPUs to power AI factories that generate intelligence for businesses and researchers, optimized AI software to run Read Article",
      "source": "NVIDIA Blog: Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3016198",
      "title": "Tesla&#8217;s Optimus robot VP is leaving the company",
      "url": "https://techcrunch.com/2025/06/06/teslas-optimus-robot-vp-is-reportedly-leaving-the-company/",
      "publishedAt": "Fri, 06 Jun 2025 20:30:46 +0000",
      "summary": "Milan Kovac, head of Tesla's Optimus humanoid robot program, is leaving the company to spend more time with family, and he said that his support for Musk and Tesla is \"ironclad.\"",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3015738",
      "title": "Amazon launches new R&#038;D group focused on agentic AI and robotics",
      "url": "https://techcrunch.com/2025/06/05/amazon-launches-new-rd-group-focused-on-agentic-ai-and-robotics/",
      "publishedAt": "Thu, 05 Jun 2025 19:48:11 +0000",
      "summary": "Amazon wants this group to develop an agentic AI framework to be used to give its warehouse robots more skills.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3015300",
      "title": "Hugging Face says its new robotics model is so efficient it can run on a MacBook",
      "url": "https://techcrunch.com/2025/06/04/hugging-face-says-its-new-robotics-model-is-so-efficient-it-can-run-on-a-macbook/",
      "publishedAt": "Wed, 04 Jun 2025 20:10:30 +0000",
      "summary": "AI dev platform Hugging Face released an open AI model for robotics called SmolVLA, which the company claims outperforms much larger models for robotics in both virtual and real-world environments.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2506.01196v2",
      "title": "OG-VLA: Orthographic Image Generation for 3D-Aware Vision-Language Action Model",
      "url": "https://arxiv.org/abs/2506.01196v2",
      "publishedAt": "2025-06-01T22:15:45Z",
      "summary": "We introduce OG-VLA, a novel architecture and learning framework that combines the generalization strengths of Vision Language Action models (VLAs) with the robustness of 3D-aware policies. We address the challenge of mapping natural language instructions and one or more RGBD observations to quasi-static robot actions.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Robotics",
        "Vision",
        "Planning"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3013274",
      "title": "Hugging Face unveils two new humanoid robots",
      "url": "https://techcrunch.com/2025/05/29/hugging-face-unveils-two-new-humanoid-robots/",
      "publishedAt": "Thu, 29 May 2025 19:28:24 +0000",
      "summary": "AI dev platform Hugging Face continued its push into robotics on Thursday with the release of two new humanoid robots.",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "https://techcrunch.com/?p=3011215",
      "title": "Why Intempus thinks robots should have a human physiological state",
      "url": "https://techcrunch.com/2025/05/25/why-intempus-thinks-robots-should-have-a-human-physiological-state/",
      "publishedAt": "Sun, 25 May 2025 14:00:00 +0000",
      "summary": "Teddy Warner, 19, has always been interested in robotics. His family was in the industry, and he says he &#8220;grew up&#8221; working in a machinist shop while in high school. Now Warner is building a robotics company of his own, Intempus, that looks to make robots a bit more human. Intempus is building tech to [&#8230;]",
      "source": "TechCrunch Robotics",
      "type": "news",
      "tags": [
        "Robotics"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2502.07631v3",
      "title": "Divide and Merge: Motion and Semantic Learning in End-to-End Autonomous Driving",
      "url": "https://arxiv.org/abs/2502.07631v3",
      "publishedAt": "2025-02-11T15:21:31Z",
      "summary": "Perceiving the environment and its changes over time corresponds to two fundamental yet heterogeneous types of information: semantics and motion. Previous end-to-end autonomous driving works represent both types of information in a single feature vector.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Autonomous Driving"
      ]
    },
    {
      "id": "http://arxiv.org/abs/2409.08031v3",
      "title": "LED: Light Enhanced Depth Estimation at Night",
      "url": "https://arxiv.org/abs/2409.08031v3",
      "publishedAt": "2024-09-12T13:23:24Z",
      "summary": "Nighttime camera-based depth estimation is a highly challenging task, especially for autonomous driving applications, where accurate depth perception is essential for ensuring safe navigation. Models trained on daytime data often fail in the absence of precise but costly LiDAR. Even vision foundation models trained on large amounts of data are unreliable in low-light conditions.",
      "source": "arXiv",
      "type": "paper",
      "tags": [
        "Autonomous Driving",
        "Vision"
      ]
    }
  ]
}